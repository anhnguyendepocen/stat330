\documentclass[handout]{beamer}

\input{../frontmatter}
\input{../commands}

\title{Set09 - Continuous distributions}

\begin{document}

<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment=NA, 
               fig.width=7, fig.height=5, 
               size='tiny', 
               out.width='0.8\\textwidth', 
               fig.align='center', 
               message=FALSE,
               echo=FALSE,
               cache=TRUE)
options(width=120)
@

<<libraries, message=FALSE, warning=FALSE, cache=FALSE>>=
library(dplyr)
library(ggplot2)
library(tidyr)
@

<<set_seed>>=
set.seed(2)
@

\frame{\maketitle}


\section{Continuous distributions}
\begin{frame}
\frametitle{Continuous distributions}
\begin{itemize}
\item Uniform
\item Exponential 
\item Gamma 
\item Normal 
\end{itemize}

\vspace{0.1in} \pause

Note: the image is always uncountably infinite.
\end{frame}


\subsection{Uniform}
\begin{frame}
\frametitle{Uniform distribution}

One of the most basic continuous densities is the \alert{uniform} density. \pause
The pdf is
\[
f(x) = \left \{ 
\begin{array}{cl}
    \frac{1}{b-a} & \text{ if } a < x < b \\
    0 & \text{ otherwise}
\end{array} \right .
\]
\pause

We use $X \sim U(a,b)$ to denote the random variable $X$ is distributed as the \emph{uniform distribution with parameters $a$ and $b$}. \pause

<<fig.width=11>>=
curve(dunif, -1, 2, 10001, axes=F, frame=TRUE, ylab="f(x)")
axis(1, c(0,1), c("a","b"))
axis(2, 1, "1/(b-a)")
@

\end{frame}


\begin{frame}
\frametitle{Uniform properties}

The cumulative distribution function is 
\[ 
F(x) = \left\{ \begin{array}{ll} 0 & x<a \\ \frac{x}{b-a} & a\le x \le b \\ 1 & x>b \end{array} \right.
\]
\pause
i.e. it's a straight line. 

\vspace{0.1in} \pause

The expectation is 
\[ 
E[X] = \int_x x \, f(x) dx = \int_a^b  x \frac{1}{b-a} dx = \frac{x^2}{b-a} |_a^b = \frac{b^2}{b-a} - \frac{a^2}{b-a} = \frac{a+b}{2}.
\]
The variance is 
\[ 
V[X] = \int_x (x-\mu)^2 f(x) dx = \int_a^b \left( x - \frac{a+b}{2} \right)^2 \frac{1}{b-a} dx = \cdots = \frac{(b-a)^{2}}{12}.
\]
\end{frame}


\begin{frame}
\frametitle{Pseudo-random number generators}

Pseudo-random number generators are typically designed to produce sequences of \alert{independent} Unif(0,1) random variables. 

\vspace{0.1in} \pause

What is the probability the next pseudo-random number is larger than 0.85? 

\vspace{0.1in} \pause

Let $X$ be the value of the next pseudo-random number \pause and assume $X\sim Unif(0,1)$. \pause
\[ 
P(X< 0.85)  = 1-P(X\le 0.85) = 1- \frac{0.85}{1-0} = 0.15.
\]
\pause

Do these pseudo-random numbers appear independent?

<<fig.width=20>>=
plot(runif(1e3), pch=19, xlab="i", ylab=expression(X[i]))
@

\end{frame}



\subsection{Exponential}
\begin{frame}
\frametitle{Exponential distribution}

A distribution commonly used to model waiting times between occurrences of \emph{rare} events, e.g. lifetimes of electrical or mechanical devices, is the exponential distribution.

\vspace{0.1in} \pause

The pdf of an exponential random variable is
\[
f(x) = \left\{ 
\begin{array}{cl}
    \lambda e^{-\lambda x} & \text{ if } x\ge 0 \\
    0 & \mbox{otherwise}
\end{array} \right.
\]
\pause

We use $X \sim Exp(\lambda)$ to denote the random variable $X$ has an exponential distribution with \alert{rate} parameter $\lambda$. 

\vspace{0.1in} \pause

You should check the following results:
\[ \begin{array}{rl}
F(x) &= \left\{ \begin{array}{ll} 0 & x<0 \\ 1-e^{-\lambda x} & x\ge 0 \end{array} \right. \\
E[X] &= 1/\lambda \\
Var[X] &= 1/\lambda^2
\end{array} \]

\end{frame}


\begin{frame}
\frametitle{Exponential pdfs}

<<>>=
d = data.frame(x = seq(0,3, length=101)) %>%
  mutate(exp1 = dexp(x),
         exp0.5 = dexp(x,rate=1/2),
         exp2   = dexp(x,rate=2)) %>%
  gather(rate, density, exp1, exp0.5, exp2) %>%
  mutate(rate = gsub("exp","", rate))

ggplot(d, aes(x, density, color=rate, linetype=rate)) + 
  geom_line() +
  theme_bw()
@

\end{frame}


\begin{frame}[fragile]
\frametitle{Print jobs}

Jobs are sent to a printer at an average of 3 jobs per hour. \pause
\begin{enumerate}
\item What is the expected time between jobs?
\item What is the probability that the next job is sent within 5 minutes?
\end{enumerate}

\vspace{0.1in} \pause

Let $T$ represent the time until the next job \pause and assume $T\sim Exp(\lambda)$ where $\lambda = 3$ jobs per hour. \pause
\begin{enumerate}
\item $E[T] = 1/\lambda = 1/3$ hours or, equivalently, 20 minutes. \pause
\item First, 5 minutes = 1/12 hours. \pause  Then 
\[ 
P(T<1/12) = 1-e^{-3\times \frac{1}{12}} = 1-e^{-\frac{1}{4}} = 0.22
\]
or, in R,
<<echo=TRUE>>=
pexp(1/12,3)
@
\end{enumerate}
\end{frame}





\begin{frame}
\frametitle{Webpage utilization}
\scriptsize

Suppose we are told that, on average, there are 2 hits per minute on a specific web page. \pause
\begin{itemize}
\item What is a reasonable distribution (model) for the time of the next hit? \pause
\item What is the expected time until the next hit? \pause
\item What is the probability we will have to wait at least a full minute before the next hit? \pause
\item What is the probability we will have to wait at least 30 seconds before the next hit? \pause
\end{itemize}

\pause

Let $Y$ be the time until the next hit. 
\begin{itemize}
\item A reasonable model is $Y\sim Exp(\lambda)$ where $\lambda$ = 2 hits per minute. \pause
\item The expected time to the next hit is $E[Y] = 1/\lambda$ = 0.5 minutes. \pause
\item The probability that we'll have to wait at least a minute is
\[ P(Y>1) = 1-P(Y\le 1) = 1-[1-e^{-\lambda \cdot 1}] = e^{-\lambda} = e^{-2} \approx 0.14. \pause \] 
\item Make sure to convert units, i.e. 30 seconds = 1/2 minute. \pause 
\[ P(Y>1/2) = e^{-\lambda/2} = e^{-1} = 0.37\]
\end{itemize}
\end{frame}





% \foilhead[-.75in]{\textcolor{blue}{Exponential Distribution: Example (continued...)}}\vspace{.01in}  
% \no {\textcolor{cyan}{How long do we have to wait at most, to observe a first hit with 
%     a probability of 0.9?}\\[.1in]  
%     {\it This is the reverse of what we have computed  
%     so far, because here we want to find a $t$, for which $P(Y \le t) = 0.9$:}
%     \begin{eqnarray*}
%     && P(Y \le t) = 0.9 \\
%     && \iff 1 - e^{-2t} = 0.9 \\
%     && \iff e^{-2t} = 0.1 \\
%     && \iff t = -0.5 \ln{0.1} \approx 1.15 \text{ (min) - that's 
%     approx. 69 seconds.}
%     \end{eqnarray*}


\begin{frame}
\frametitle{Memoryless property of the exponential distribution}

The exponential distribution has the \alert{memoryless property} since 
\[ \begin{array}{rl}
P(X\ge i+j|X\ge j) &= \frac{P(X\ge i+j,X\ge j)}{P(X\ge j)} = \frac{P(X\ge i+j)}{P(X\ge j)} \\
&= \frac{e^{-\lambda(i+j)}}{e^{-\lambda j}} = \frac{e^{-\lambda i} e^{-\lambda j}}{e^{-\lambda j}} = e^{-\lambda i}  \\
&= P(X\ge i)
\end{array} \]

\pause

% Thus, when using the exponential distribution
% \begin{itemize}
% \item it does not matter when we start observing \pause and
% \item it does not matter if we observe for a while and then restart the timer.
% \end{itemize}

Suppose $Y$ is the next web page hit and we assume $Y\sim Exp(\lambda)$. \pause
If we have no hits in the first minute, what is the probability we will have a hit in the second minute? \pause

\vspace{0.1in} \pause

We have 
\[ \begin{array}{rl}
P(Y<2|Y\ge 1) &= 1- P(Y\ge 2|Y\ge 1) = 1-P(Y\ge 1) = P(Y<1) = 1-e^{-\lambda}
\end{array} \]
\end{frame}

% 
% 
% \foilhead[-.8in]{\textcolor{blue}{Gamma Distribution}}\vspace{.1in} 
% \no This distribution is used to model total waiting time of a procedure that consists of 
% $\alpha$ independent stages, each stage with a waiting time having a distribution $Exp_{\lambda}$.\\[.1in]
% \no Then the total time has a Gamma disribution with parameters $\alpha$ and $\lambda$.\\[.1in]
% \no  {\textcolor{magenta}{Gamma density}} {\textcolor{cyan}{A random variable $X$ has {\it gamma density} if}}\\[.15in]
% \hspace*{1.5in} $ f(x)= \frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda x},\qquad x>0$\\[.15in]
% \no {\textcolor{cyan}{$\lambda$ is called the \emph{rate parameter} and $\alpha$ is called the \emph{shape parameter}}}\\[.1in]
% \no {\textcolor{cyan}{$\Gamma(\alpha)$ is the {\textcolor{red}{Gamma function}}, an integral that is defined on p.433 (Baron)}}\\[.1in]
% \no We say that the random variable $X \sim Gamma(\alpha,\lambda)$\\[.1in]
% \no When $\alpha$ is an integer (this is the case with most applications we'll discuss), the gamma random variable can be represented as the sum of $\alpha \ iid\ Exp_{\lambda}$ random variables. It follows that $Gam_{1,\lambda} \equiv Exp_{\lambda}$
% \foilhead[-.8in]{\textcolor{blue}{Density functions of gamma variables for different 
%     shape parameters 0.5, 1, and 1.5.}}\vspace{10pt}
%     \centerline{\includegraphics[scale=.7]{gamma_pdf2.pdf}}
% \foilhead[-.75in]{\textcolor{blue}{Properties of the  Gamma Distribution}}\vspace{.1in} 
% \no {\textcolor{red}{Mean}} and {\textcolor{red}{Variance}} are obtained using integration (see p. 85/86 of Baron). They 
% are:
% \vspace*{-.2in}
% \begin{eqnarray*}
%     E[X] &=& \frac{\alpha}{\lambda} \\
%     Var[X] &=& \frac{\alpha}{\lambda^{2}}
% \end{eqnarray*}
% The {\textcolor{red}{cdf}},  $Gam_{\alpha,\lambda}(t) = F_{X}(t)$ is of the form
% $$ F_{X}(t)=\int_0^t f(x)dx=\frac{\lambda^\alpha}{\Gamma(\alpha)}\int_0^tx^{\alpha-1}e^{-\lambda x}dx$$
% The computation of the cdf is not trivial. Tabulated values of the \emph{incomplete Gamma function} is to evaluate the gamma
% cdf. It can be computed for small integer values of $\alpha$ by repeated integration by parts.



\end{document}   














