\documentclass[20pt,landscape]{foils}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{color}
\usepackage{hyperref}
%\usepackage{pause}
\usepackage{graphicx}
\usepackage{epsfig}
%\usepackage{geometry}
%\geometry{headsep=3ex,hscale=0.9}
\newcommand{\bd}{\textbf}
\newcommand{\no}{\noindent}
\newcommand{\un}{\underline}
\newcommand{\bi}{\begin{itemize}}
\newcommand{\ei}{\end{itemize}}
\newcommand{\be}{\begin{enumerate}}
\newcommand{\ee}{\end{enumerate}}
\newcommand{\bc}{\begin{center}}
\newcommand{\ec}{\end{center}}
\newcommand \h {\hspace*{.3in}}
\newcommand{\bul}{\hspace*{.1in}{\textcolor{red}{$\bullet$ \ }}}
\newcommand{\xbar}{\bar{x}}
\rightheader{Stat 330 (Fall 2015): slide set 18}

\begin{document}
\LogoOff

\foilhead[1.3in]{}
\centerline{\LARGE \textcolor{blue}{Slide set 18}}
\vspace{0.3in}
\centerline{\large Stat 330 (Fall 2015)}
\vspace{0.2in}
\centerline{\tiny Last update: \today}
\setcounter{page}{0}


\foilhead[-.8in]{\textcolor{blue}{Stochastic Processes}}
\no {\textcolor{blue}{Review:} What is a Random variable? \\[.15in]
\no  {\textcolor{magenta}{Definition:} A stochastic process is a set of random variables indexed by some indices, particularly time $t$, and is usually denoted by $X(t)$.\\[.15in]
\no {\textcolor{magenta}{Some remarks:}}\\[.15in]
\no 1. Stochastic process is a mathematical model of reality.\\[.15in]
\no 2. Modeling usually requires somehow specifying the joint distribution 
$(X(t_1),\cdots, X(t_k))$ or $P(X_1\in A_1, \cdots, X_k\in A_k)$\\[.15in]
\no 3. Values of $X(t)$ are called {\textcolor{magenta}{states}}, the set of all possible values for $X(t)$ is called the {\textcolor{magenta}{state space}}. \\[.15in]
\no  {\textcolor{cyan} {The example about 'hits on a webpage' is a typical example of stochastic process, and it has a special name:}} {\textcolor{red} {Poisson Process}}.



\foilhead[-.8in]{\textcolor{blue}{Poisson Process}}
\no  {\textcolor{magenta}{Review: What is Exponential distribution? and Poisson distribution?}}  \\[.1in]
\no  1. {\textcolor{magenta}{Exponential}}:  $P(T\leq t)=1-e^{-\lambda t}$ for all $t\geq 0$ where $T$ is waiting time for rare event to happen (once).\\[.1in]
\no 2. {\textcolor{magenta}{Poisson}}: $P(X=k)=e^{-\lambda}\lambda^x/x!$ where $X$ is the number of observations of rare event during certain time period (or space).\\[.1in]
\no 3. \emph{pdf} of Exponential distribution: $f_T(t)=\lambda e^{-\lambda t}$ for $t\geq 0$, and $\lambda$ is the rate,  $1/\text{time}$. What is $E(T)$, and $\text{Var}(T)$? What is $E(X)$ and $\text{Var}(X)$)\\[.1in]
\no 4. Lack of memory property for Exponential: $$P(T>t+s|T>t)=P(T>s)$$ (this is key for Poisson process later)\\[.1in]
\no 5.  Exponential race: $P(\min (S,T)>t)=P(S>t, T>t)=e^{-(\lambda+\mu)t}$ if $T,S$ independent. What about $P(\min (T_1,\cdots, T_n)>t)$? 
\foilhead[-.8in]{\textcolor{blue}{Poisson process}}
\no  {\textcolor{magenta}{Definition:}  A stochastic process $X(t)$ is called {\it homogenous Poisson
    process with rate $\lambda$}, if
    \begin{enumerate}
	\item for $t > 0$, $X(t)$ takes values in $\{ 0,1,2,3, \ldots \}$.
	\item {distribution depends only on length of interval} for any $0 \le t_{1} < t_{2}$:
	\[
	X(t_{2}) - X(t_{1}) \sim Po_{\lambda (t_{2} - t_{1})}
	\]
	\item {non-overlapping intervals are independent} for any $0
	\le t_{1} < t_{2} \le t_{3} < t_{4}$
	\[
	X(t_{2}) - X(t_{1}) \text{ is independent from } X(t_{4}) -X(t_{3})
	\]
    \end{enumerate}
\no Jargon: $X(t)$ is a ``counting process'' with independent Poisson
increments.
 

\foilhead[-.8in]{\textcolor{blue}{Example}}
\no $\clubsuit$ A counter of the number of hits on our webpage is an example for a Poisson process with rate $\lambda=2$/min. \\[.1in]
\no $\heartsuit$ Here \emph{arrival} times are generated from $Exp(2).$ $X(t)$ \emph{counts} numbers of hits until time $t$ min.\\[.1in]
\no \hspace*{2in} \includegraphics*[scale=.8]{poisson_counter.pdf}
\vspace*{-.4in}

\no $\diamondsuit$ For example, we find that  $X(t)=3$ for $t\in [5,8]$ minutes; i.e., only 3 hits upto any time within 5 to 8 minutes.
\foilhead[-.8in]{\textcolor{blue}{Example (cont'd)}}
\no {\textcolor{magenta}{Remarks} \\[.1in]
\no 1. $X(t)$ can be thought of as the number of occurrences until time $t$.\\[.1in]
\no 2. Similarly, $X(t_{2}) - X(t_{1})$ is the number of occurrences in the interval $(t_{1}, t_{2}]$.\\[.1in]
\no 3. Assume $X(0) = 0$\\[.1in]
\no 4. The distribution of $X(t)$ is Poisson with rate $\lambda t$, since:
   $$X(t) = X(t) - X(0) \sim Po_{\lambda(t-0)}$$\\[.1in]
  
  
\foilhead[-.8in]{\textcolor{blue}{Example (Cont'd)}}  
\no {\textcolor{red}{Based on the last example:} \\[.1in]
For a given Poisson process $X(t)$ we define {\it occurrences}
$$
    O_{0}=0 ,\    O_{j} = \text{time of the } j^{th} \text{occurrence} =\text{the first } t\ \text{ for which } X(t) \ge j
$$
and the {\it inter-arrival time} between successive hits:
$$
    I_{j} = O_{j} - O_{j-1} \text{ for } j = 1, 2, \ldots
$$
The time until the $k^{th}$ hit $O_{k}$ is therefore given as the sum of
inter-arrival times $O_{k} = I_{1} + \ldots + I_{k}$.




\foilhead[-.8in]{\textcolor{blue}{Equivalence theorem }}
\no {\textcolor{red}{Equivalence theorem:} \\[.1in]
\no $X(t)$ is a Poisson process with rate $\lambda$ \textbf{iff} the inter-arrival times $I_{1}, I_{2},
    \ldots$ are i.i.d. $Exp_{\lambda}$.\\[.1in]
\no {\textcolor{red}{Corollary:} \\[.1in]    
\no The time until the $k$th hit $O_{k}$ is an Erlang$_{k,
\lambda}$ distributed variable, $\iff$ $X(t)$ is a Poisson process
with rate $\lambda$.\\[.1in]
\no {\textcolor{red}{Note:} This theorem is very important! - it links the Poisson, Exponential,
and Erlang distributions tightly together!
%\no {\textcolor{red}{Some thoughts:}\\[.1in]
%\no \bul Why Poisson so important?!\\[.1in]
%\no \bul We mention homogeneous Poisson process; What is meant by {\textcolor{magenta}{homogeneous}}?\\[.1in]
%\no \bul What is a  nonhomogeneous process?   

\foilhead[-.8in]{\textcolor{blue}{Example}}\vspace{.5cm}
\no  {\textcolor{magenta}{Hits on a website:}} {\textcolor{cyan}{Hits on a popular Web page occur according to a Poisson Process with
a rate of 10  hits/min. One begins observation at exactly noon.}}\\[.1in]
\no 1. {\textcolor{cyan}{Evaluate the probability of 2 or less hits in the first minute.}}\\[.1in]
{\it
Let $X$ be the number of hits in the first minute, then $X$ is a
Poisson variable with $\lambda = 10$:
\[
P(X \le 2) = Po_{10}(2) = e^{-10} + 10 \cdot  e^{-10}  + 10^{2}/2
e^{-10} = 0.0028.
\]
}\\[.1in]
\no 2. {\textcolor{cyan}{Evaluate the probability that the time till the first hit exceeds 10 seconds.}}\\[.1in]
{\it Let $Y$ be the time until the first hit - then $Y$ has an
Exponential distribution with parameter $\lambda = 10$ per minute or
$\lambda = 1/6$ per second.
\[
P(Y \ge 10) = 1 - P(Y \le 10) = 1 - (1 - e^{-10 \cdot 1/6}) =
e^{-5/3} = 0.1889.
\]}
\no 3. {\textcolor{cyan}{Evaluate the mean and the variance of the time till the 4th hit.}}\\[.1in]
{\it Let $T$ be the time till the 4th hit. Then $T$ has an Erlang
distribution with stage parameter $k = 4$ and $\lambda = 10$ per minute.
\begin{eqnarray*}
    E[T] &=& \frac{k}{\lambda} = \frac{4}{10} = 0.4 \text{ minutes} \\
    Var[T] &=& \frac{k}{\lambda^{2}} = \frac{4}{100} = 0.04 \text{minutes}^{2}.
\end{eqnarray*}}
%
\no 4. {\textcolor{cyan}{Evaluate the probability that the time till the 4th hit exceeds 24 seconds.}}
\no Need $P(T > 24/60)$ where $T \sim Erlang(4,10)$ and $T$ is in minutes; so we'll use the Gamma-Poisson formula:
\begin{eqnarray*}
    P(T > 0.4) &=& P(X<4) \ \ \mbox{ where } X \sim Poi(\lambda \cdot t)\\
    &=& P(X \le 3)\ \mbox{where}\ X \sim Poi(10 \cdot 0.4)\\
    &=& Po_{4}(3)=0.433% \ \ \text{Website table,p.786 or Baron p.384}
\end{eqnarray*}
%\newpage
%\no 5. {\textcolor{cyan}{The number of hits in the first hour is Poisson with mean 600. You would like to know the
%probability of more than 650 hits. Exact calculation isn't really feasible. So approximate this
%probability and justify your approximation.}}\\[.1in]
%{\it Recall that a Poisson distribution with large rate $\lambda$ can be
%approximated by a normal distribution with mean $\mu = \lambda$ and variance $\sigma^{2} =
%\lambda$.\\[.1in]
%\no Then $X \stackrel {\text{approx}}{\sim} N(600,600) \rightarrow
%Z := \frac{X - 600}{\sqrt{600}} \stackrel {\text{approx}}{\sim} N(0,1)$.\\[.1in]
%\no Then:
%\begin{eqnarray*}
%P(X > 650) &&= 1 - P(X \le 650) = 1 - P \left ( Z \le
%\frac{650-600}{\sqrt{600}} \right ) \approx\\
%&&\approx 1 - \Phi(2.05)\\
%&& = 1-0.9798 = 0.0202.\ \ \text{Webpage table, p.789 or Baron p. 386}
%\end{eqnarray*}}
%
%\foilhead[-.8in]{\textcolor{blue}{Poisson Process: Conditioning}}
%\no {\textcolor{cyan}{Poisson process possesses an interesting property that is consistent with thinking of it as "random occurrences" in time $t$, which leads to the conditioning theorem}}\\[.1in]
%\no {\textcolor{magenta}{Theorem:}}   Let $X(t)$ be a Poisson process.
%    Given that $X(T) = k$, the conditional distribution of the time of the $k$ occurrences
%    $O_{1}, \ldots, O_{k}$ is the same as the distribution of $k$
%    ordered independent standard uniform variables $U_{(1)}, U_{(2)},
%    \ldots, U_{(k)}$.\\[.1in]
%\no $\clubsuit$ In other word, given that there were $k$ arrivals, the set of arrival times is the same as the locations of $k$ darts thrown at random on the interval $[0,t]$. \\[.1in]
%\no $\spadesuit$ This tells us a way to simulate a Poisson process with rate $\lambda$ on the interval
%$(0,T)$.
%\foilhead[-.8in]{\textcolor{blue}{Simulating a Poisson Process}}
%\begin{itemize}
%\addtolength{\itemsep}{-0.6\baselineskip}
%    \item[\bul] first, draw a Poisson value $w$ from $Po_{\lambda T}$. 
%   ( This tells us, how many uniform values $U_{i}$ we need to simulate )
%    \item[\bul ] second, generate $w$ many standard uniform values
%    $u_{1}, \ldots, u_{w}$
%    \item[\bul] define $o_{i} = T \cdot u_{(i)}$, where $u_{(i)}$ is the
%    $i$th smallest value among $u_{1}, \ldots, u_{w}$.
%\end{itemize}
%\vspace*{-.3in}
%
%\no $\heartsuit$ The above theorem tells us, that, if we pick $k$ values at
%random from an interval $(0,t)$ and order them, we can assume that the distance
%between two successive values has an exponential distribution with
%rate $\lambda = k/t$.\\[.1in]
%\no $ \diamondsuit$ So far, we are looking only at arrivals of events. Besides that, we
%could, for example, look at the number of surfers that are on our web
%site at the same time.\\[.1in]
%\no $\clubsuit$ There, we have departures as well  and, related to that, the time each
%surfer stays - which we will call  {\textcolor{magenta}{service time}} (from the
%perspective of the web server). 
    
 
 
\end{document}




