\documentclass[handout]{beamer}

\input{../frontmatter}
\input{../commands}

\title{Set12 - Stochastic processes}

\begin{document}

<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment=NA, 
               fig.width=7, fig.height=5, 
               size='tiny', 
               out.width='0.8\\textwidth', 
               fig.align='center', 
               message=FALSE,
               echo=FALSE,
               cache=TRUE)
options(width=120)
@

<<libraries, message=FALSE, warning=FALSE, cache=FALSE>>=
library(dplyr)
library(ggplot2)
library(tidyr)
@

<<set_seed>>=
set.seed(2)
@

\frame{\maketitle}


\section{Stochastic Processes}
\begin{frame}
\small

\begin{definition}
A \alert{stochastic process} is a collection of random variables index by ``time'' $t$, i.e.
\[ \{ X(t,\omega)\mid t\in\mathcal{T} \} \]
where
\begin{itemize}[<+->]
\item $\mathcal{T}$ is a set of possible times, e.g. $[0,\infty),\{0, 1, 2, ...\}$.
\item $\omega\in\mOmega$ is an outcome from the whole sample space $\mOmega$.
\item Values of $X(t,\omega)$ are called \alert{states}.
\item For any fixed time $t$, we see a random variable $X_t(\omega)$, a function of an outcome.
\item For any fixed $\omega$, we have a function of time $X_\omega(t)$. This function is called a \alert{realization, sample path, or trajectory} of a process $X(t,\omega)$.
\item $X(t,\omega)$ is \alert{discrete-state} (\alert{continuous-state}) if $X_t(\omega)$ is discrete (continuous).
\item $X(t,\omega)$ is \alert{discrete-time} (\alert{continuous-time)} if $\mathcal{T}$ is discrete (continuous).
\end{itemize}
\end{definition}
\end{frame}


\begin{frame}
\frametitle{Examples}
\begin{itemize}
\item CPU usage, in percents, is a continuous-state and continuous-time process.
\item Let $X(t,\omega)$ be the amount of time required to serve
the $t$-th customer at a Subway. This is a discrete-time, continuous-state stochastic
process, as $t\in\mathcal{T}=\{1,\,2,\,...\}$ and the state space
is $(0,\infty)$.
\item Let $X(t,\omega)$ be the result of tossing a fair coin in the $t$-th
trial (1 for head, 0 for tail), this is then a discrete-time, discrete-state
stochastic process.
\item Let $X(t,\omega)$ be the reported temperature (rounded to the nearest integer) by radio at time $t$,
it is then a continuous-time, discrete-state stochastic process.
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Markov processes}

\begin{definition}
A stochastic process $X(t)$ is \alert{Markov} if for any $t_1<t_{2}<...<t_n<t$ and any sets $A, A_1,\ldots,A_n$
\[ 
P(X(t)\in A|\, X(t_1)\in A_1,\,...\,,\, X(t_n)\in A_n)=P(X(t)\in A|\, X(t_n)\in A_n).
\]
\end{definition}

\vspace{0.1in} \pause

In other words, it means that the conditional distribution of $X(t)$
is the same under two different conditions:

\begin{itemize}
\item conditional on  the observations of the process $X$ at several moments in the past;
\item conditional only on the \emph{latest} observations of $X$.
\end{itemize}

\vspace{0.1in} \pause

Implies that the distribution of $X(t)$ at time $t$ depends only on the distribution of $X(t)$ at time $t_n$.


\end{frame}



\begin{frame}
\frametitle{Examples}
\begin{itemize}
\item ({\textcolor{magenta}{Internet Connections}}). Let $X(t)$ be the total number
of internet connections registered by some internet service provider
by the time $t$. Typically, people connect to the internet at random
times, regardless of how many connections have already been made.
Therefore, the number of connections in a minute will only depend
on the current number.
\item ({\textcolor{magenta}{Stock Prices}}). The following is the Dow Jones Industrial
Average recorded on Oct 6, 2010 from 9:30am ET to 12:22pm
ET. Let $Y(t)$ be the value of DJI at time $t$. The fact that the market has been falling several periods before 11:00 p.m. may help you to predict the dip of $Y(t)$. Thus this process is not Markov.
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{Markov chains}
\small

\begin{definition}
A \alert{Markov chain} is a discrete-time, discrete-state Markov process.

\pause

% \end{definition}
%
% Thus,
% {\small
% \[ 
% P(X(t+1)=x_{t+1}|X(t)=x_t,\ldots,X(1)=x_1) = P(X(t+1)=x_{t+1}|X(t)=x_t)
% \]
% }
% \begin{definition}
\begin{itemize}
\item The \alert{transition (probability) matrix}  is 
\[ 
p_{ij}(t) = P(X_{t+1}=j|X_t=i).
\]

\item The \alert{$h$-step transition probability} is 
\[ 
p_{ij}^{(h)}(t) = P(X_{t+h}=j|X_t=i).
\]

\item A Markov chain is \alert{homogenous} if all its transitions probabilities are independent of $t$, i.e. 
\[ 
p_{ij}(t) = p_{ij}. 
\]
\end{itemize}
\end{definition}
\end{frame}


\begin{frame}
\frametitle{Example Markov chain}

In the summer, each day in Ames is either sunny or rainy. 
A sunny day is followed by another sunny day with probability 0.7, whereas a rainy day is followed by a sunny day with probability 0.4.
It rains on Monday. 
Make weather forecasts for Tuesday, Wednesday, and Thursday, using a homogeneous Markov chain model.

\vspace{0.1in} \pause

Let 
\[ 
X(t) = \left\{ \begin{array}{ll}
0 & \mbox{if it rains on day $t$} \\
1 & \mbox{if it sunny on day $t$}
\end{array} \right.
\]
Then a homogeneous Markov chain model has transition matrix 
\[
  p = \bordermatrix{
    & 0 & 1 \\
    0 & 0.4 & 0.6 \\
    1 & 0.3 & 0.7
  }
\]

\end{frame}


% \foilhead[-.8in]{\textcolor{blue}{Markov Chains : Example}} 
% \no In the summer, each day in Ames is either sunny or rainy. A sunny
% day is followed by another sunny day with probability 0.7, whereas
% a rainy day is followed by a sunny day with probability 0.4. It rains
% on Monday. Make weather forecasts for Tuesday, Wednesday, and Thursday, using a homogeneous Markov chain model.\\[.1in]
% \no Let 1=''sunny'' and 2=''rainy'' and M,T,W,R denotes days of the week.\\[.1in]
% Given $p_{11}=.7$; it follows that for the complementary event  $p_{12}=.3$\\[.1in]
% Similarly, given $p_{21}=.4$ it follows that $p_{22}=.6$\\[.15in]
% {\textcolor{blue}{Forecast for Tuesday:}}\\[.1in]
% Consider Monday(M) to Tuesday(T) as a one-step transition:\\[.1in]
% \hspace*{1in} $P(\text{T sunny}|\text{M rainy})=p_{21}=.4$\\[.1in]
% \hspace*{1in} $P(\text{T rainy}|\text{M rainy})=p_{22}=.6$\\[.1in]
% {\textcolor{magenta}{Prediction:}} 60\% chance of rain for Tuesday.
% \newpage
% \no {\textcolor{blue}{Forecast for Wednesday:}}\\[.01in]
% Consider Monday(M) to Wednesday(W) as a 2-step transition:\\[.1in]
% $P(\text{W sunny}|\text{M rainy})=p_{21}^{(2)}=$ ({\textcolor{magenta}{By Total Probability Law}})\\[.1in]
% \hspace*{1in} $P(\text{W sunny}|\text{T rainy},\text{M rainy})\cdot P(\text{T rainy}|\text{M rainy})$\\
% \hspace*{2.5in} $+P(\text{W sunny}|\text{T sunny},\text{M rainy})\cdot P(\text{T sunny}|\text{M rainy})$ \\[.1in]
% \no Using {\textcolor{magenta}{Markov property}}, above equals to\\[.1in]
% {\small $P(\text{W sunny}|\text{T rainy})\cdot P(\text{T rainy}|\text{M rainy})+P(\text{W sunny}|\text{T sunny})\cdot P(\text{T sunny}|\text{M rainy})$} \\[.1in]
% \hspace*{1.5in} $=p_{21}\cdot p_{22}+p_{11} \cdot p_{21}=(.4)(.6)+(.7)(.4)=.52$\\[.1in]
% For the complementary event, $P(\text{W rainy}|\text{M rainy})=p_{21}^{(2)}=1-.52=.48$\\[.1in]
% {\textcolor{magenta}{Prediction:}} 48\% chance of being sunny on Wednesday.\\[.1in]
% Using this method, computations of 3-step probabilities follow similar arguments:
% $p_{21}^{(3)}=p_{21}\cdot p_{22}^{(2)}+p_{11} \cdot p_{22}^{(2)}=(.4)(.48)+(.7)(.52)=.556$\\[.1in]
% {\textcolor{magenta}{Prediction:}} 44.4\% chance of rain for Thursday.
% \foilhead[-.8in]{\textcolor{blue}{Transition Probability Matrix}} 
% \no Let $\{1,\,2,\,...,\, n\}$ be the state space. The 1-step
% transition probability matrix is
% \[P=\begin{pmatrix}p_{11} & p_{12} & \cdots & p_{1n}\\
% p_{21} & p_{22} & \cdots & p_{2n}\\
% \vdots & \vdots & \ddots & \vdots\\
% p_{n1} & p_{n2} & \cdots & p_{nn}
% \end{pmatrix}.\]
% The element from the $i$-th row and $j$-th column is $p_{ij}$,
% which is the transition probability from state $i$ to state $j$.
% Similarly, one can define a $h$-step transition probability matrix\\
% \[P^{(h)}=\begin{pmatrix}p_{11}^{(h)} & p_{12}^{(h)} & \cdots & p_{1n}^{(h)}\\
% p_{21}^{(h)} & p_{22}^{(h)} & \cdots & p_{2n}^{(h)}\\
% \vdots & \vdots & \ddots & \vdots\\
% p_{n1}^{(h)} & p_{n2}^{(h)} & \cdots & p_{nn}^{(h)}
% \end{pmatrix}.\]
% \newpage
% \no Using the matrix notation the following results follow:\\[.15in]
% \bul 2-step transition matrix $P^{(2)}=P\cdot P=P^{2}$\\[.1in]
% \bul $h$-step transition matrix $P^{(h)}=P^{h}$\\[.1in]
% \bul  The distribution of $X(h)$ is given by $P_{h}=P_{0}P^{h}$\\[.1in]
% {\textcolor{blue}{Rain in Ames Example:}}\\
% \[P=\begin{pmatrix}.7 & .3 \\
% .4 & .6\\
% \end{pmatrix}, \ \ P^{(2)}=\begin{pmatrix}.7 & .3 \\
% .4 & .6\\
% \end{pmatrix} \cdot \begin{pmatrix}.7 & .3 \\
% .4 & .6\\
% \end{pmatrix}=\begin{pmatrix} .61 &  .39 \\ .52 & .48 \end{pmatrix}\]
%  \[P^{(3)}=\begin{pmatrix} .61 &  .39 \\ .52 & .48 \end{pmatrix} \cdot \begin{pmatrix} .7 & .3 \\
% .4 & .6\\
% \end{pmatrix}=\begin{pmatrix} .583 & .417  \\ .556 & .444 \end{pmatrix}\]\\
% Just read-off values needed for predictions: \\[.1in]
% \hspace*{1.5in} $P(\text{W rainy}|\text{M rainy})=p_{22}^{(2)}=.48$\\[.1in] 
% \hspace*{1.5in} $P(\text{R sunny}|\text{M rainy})=p_{21}^{(3)}=.556$ 




\end{document}




