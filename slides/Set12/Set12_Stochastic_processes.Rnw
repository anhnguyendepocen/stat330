\documentclass[handout]{beamer}

\input{../frontmatter}
\input{../commands}

\title{Set12 - Stochastic processes}

\begin{document}

<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment=NA, 
               fig.width=7, fig.height=5, 
               size='tiny', 
               out.width='0.8\\textwidth', 
               fig.align='center', 
               message=FALSE,
               echo=FALSE,
               cache=TRUE)
options(width=120)
@

<<libraries, message=FALSE, warning=FALSE, cache=FALSE>>=
library(dplyr)
library(ggplot2)
library(tidyr)
@

<<set_seed>>=
set.seed(1)
@

\frame{\maketitle}


\section{Stochastic Processes}
\begin{frame}
\small

\begin{definition}
A \alert{stochastic process} is a collection of random variables index by ``time'' $t$, i.e.
\[ \{ X(t,\omega)\mid t\in\mathcal{T} \} \]
where
\begin{itemize}[<+->]
\item $\mathcal{T}$ is a set of possible times, e.g. $[0,\infty),\{0, 1, 2, ...\}$.
\item $\omega\in\mOmega$ is an outcome from the whole sample space $\mOmega$.
\item Values of $X(t,\omega)$ are called \alert{states}.
\item For any fixed time $t$, we see a random variable $X_t(\omega)$, a function of an outcome.
\item For any fixed $\omega$, we have a function of time $X_\omega(t)$. This function is called a \alert{realization, sample path, or trajectory} of a process $X(t,\omega)$.
\item $X(t,\omega)$ is \alert{discrete-state} (\alert{continuous-state}) if $X_t(\omega)$ is discrete (continuous).
\item $X(t,\omega)$ is \alert{discrete-time} (\alert{continuous-time)} if $\mathcal{T}$ is discrete (continuous).
\end{itemize}
\end{definition}
\end{frame}


\begin{frame}
\frametitle{Examples}
\begin{itemize}
\item CPU usage, in percents, is a continuous-state and continuous-time process.
\item Let $X(t,\omega)$ be the amount of time required to serve
the $t$-th customer at a Subway. This is a discrete-time, continuous-state stochastic
process, as $t\in\mathcal{T}=\{1,\,2,\,...\}$ and the state space
is $(0,\infty)$.
\item Let $X(t,\omega)$ be the result of tossing a fair coin in the $t$-th
trial (1 for head, 0 for tail), this is then a discrete-time, discrete-state
stochastic process.
\item Let $X(t,\omega)$ be the reported temperature (rounded to the nearest integer) by radio at time $t$,
it is then a continuous-time, discrete-state stochastic process.
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Markov processes}

\begin{definition}
A stochastic process $X(t)$ is \alert{Markov} if for any $t_1<t_{2}<...<t_n<t$ and any sets $A, A_1,\ldots,A_n$
\[ 
P(X(t)\in A|\, X(t_1)\in A_1,\,...\,,\, X(t_n)\in A_n)=P(X(t)\in A|\, X(t_n)\in A_n).
\]
\end{definition}

\vspace{0.1in} \pause

In other words, it means that the conditional distribution of $X(t)$
is the same under two different conditions:

\begin{itemize}
\item conditional on  the observations of the process $X$ at several moments in the past;
\item conditional only on the \emph{latest} observations of $X$.
\end{itemize}

\vspace{0.1in} \pause

Implies that the distribution of $X(t)$ at time $t$ depends only on the distribution of $X(t)$ at time $t_n$.


\end{frame}



\begin{frame}
\frametitle{Examples}
\begin{itemize}
\item ({\textcolor{magenta}{Internet Connections}}). Let $X(t)$ be the total number
of internet connections registered by some internet service provider
by the time $t$. Typically, people connect to the internet at random
times, regardless of how many connections have already been made.
Therefore, the number of connections in a minute will only depend
on the current number.
\item ({\textcolor{magenta}{Stock Prices}}). The following is the Dow Jones Industrial
Average recorded on Oct 6, 2010 from 9:30am ET to 12:22pm
ET. Let $Y(t)$ be the value of DJI at time $t$. The fact that the market has been falling several periods before 11:00 p.m. may help you to predict the dip of $Y(t)$. Thus this process is not Markov.
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{Markov chains}
\small

\begin{definition}
A \alert{Markov chain} is a discrete-time, discrete-state Markov process.

\pause

% \end{definition}
%
% Thus,
% {\small
% \[ 
% P(X(t+1)=x_{t+1}|X(t)=x_t,\ldots,X(1)=x_1) = P(X(t+1)=x_{t+1}|X(t)=x_t)
% \]
% }
% \begin{definition}
\begin{itemize}
\item The \alert{transition (probability) matrix}  is 
\[ 
p_{ij}(t) = P(X_{t+1}=j|X_t=i).
\]

\item The \alert{$h$-step transition probability} is 
\[ 
p_{ij}^{(h)}(t) = P(X_{t+h}=j|X_t=i).
\]

\item A Markov chain is \alert{homogenous} if all its transitions probabilities are independent of $t$, i.e. 
\[ 
p_{ij}(t) = p_{ij}. 
\]
\end{itemize}
\end{definition}
\end{frame}


\begin{frame}
\frametitle{Example Markov chain}

In the summer, each day in Ames is either sunny or rainy. 
A sunny day is followed by another sunny day with probability 0.7, whereas a rainy day is followed by a sunny day with probability 0.4.
It rains on Monday. 
Make weather forecasts for Tuesday, Wednesday, and Thursday, using a homogeneous Markov chain model.

\vspace{0.1in} \pause

Let 
\[ 
X(t) = \left\{ \begin{array}{ll}
1 & \mbox{if it is sunny on day $t$} \\
2 & \mbox{if it rains on day $t$} 
\end{array} \right.
\]
Then a homogeneous Markov chain model has transition matrix 
\[ % I'd like to do this with bordermatrix
  p = \left( \begin{array}{cc} 0.7 & 0.3 \\ 0.4 & 0.6 \end{array} \right)
\]
\pause
which means 
{\tiny
\[ \begin{array}{rl}
P(X(t)=1|X(t-1)=1) &= 0.7 \\
P(X(t)=2|X(t-1)=1) &= 0.3 \\
P(X(t)=2|X(t-1)=2) &= 0.6 \\
P(X(t)=1|X(t-1)=2) &= 0.4 
\end{array} \]
}
\end{frame}


\begin{frame}
\frametitle{Tuesday forecast}

Let 
\begin{itemize}
\item $t=0$ be Monday
\item $t=1$ be Tuesday
\end{itemize}
\pause
Then we know 
\[ 
P(\mbox{M rain}) = P(X(0)=2) = 1
\]
because (we know) it rained on Monday. 

\vspace{0.1in} \pause

Thus, our Tuesday forecast is 
\[
P(\mbox{T rain}|\mbox{M rain}) = P(X(1)=2|X(0)=2) = 0.6
\]
\pause
i.e. a 60\% chance of rain \pause and a 40\% chance of sun since
\[ \begin{array}{rl}
P(\mbox{T sun}|\mbox{M rain}) &= 1-P(\mbox{T rain}|\mbox{M rain}) \\
&= 1-P(X(1)=2|X(0)=2) \\
&= 1-0.6=0.4.
\end{array} \]


\end{frame}



\begin{frame}
\frametitle{Wednesday forecast}
\small

Let 
\begin{itemize}
\item $t=2$ be Wednesday
\end{itemize}
and we know
\[ 
P(X(1)=2|X(0)=2) = 0.6
\]
then 
{\tiny
\[ \begin{array}{rll}
P(X(2)=2|X(0)=2) =& 
P(X(2)=2|X(1)=2,X(0)=2)P(X(1)=2|X(0)=2) \\ 
&+ 
P(X(2)=2|X(1)=1,X(0)=2)P(X(1)=1|X(0)=2) & \mbox{by Law of Total Probability} \\ \\
=& P(X(2)=2|X(1)=2)P(X(1)=2|X(0)=2) \\
&+ 
P(X(2)=2|X(1)=1)P(X(1)=1|X(0)=2) & \mbox{by Markov property} \\ \\
=& 0.6\times 0.6 + 0.3\times 0.4 \\
=& 0.48
\end{array}\]
}
i.e. a 48\% chance of rain on Wednesday 
\pause
and thus
\[
P(X(2)=1|X(0)=2) = 1-P(X(2)=2|X(0)=2) = 1-0.48 = 0.52
\]

\end{frame}




\begin{frame}
\frametitle{Thursday forecast}
\small

Let 
\begin{itemize}
\item $t=3$ be Thursday
\end{itemize}
and we know
\[ 
P(X(2)=2|X(0)=2) = 0.48
\]
then 
{\tiny
\[ \begin{array}{rll}
P(X(3)=2|X(0)=2) =& 
P(X(3)=2|X(2)=2)P(X(2)=2|X(0)=2) \\
& + P(X(3)=2|X(2)=1)P(X(2)=1|X(0)=2)  \\ \\ 
=& 0.6\times 0.48 + 0.3\times 0.52 \\
=& 0.444
\end{array}\]
}
i.e. 44.4\% chance of rain on Thursday 
\pause
and thus
\[
P(X(2)=1|X(0)=2) = 1-P(X(2)=2|X(0)=2) = 1-0.444 = 0.556
\]

\end{frame}



\begin{frame}[fragile]
\frametitle{Simulate an answer}

<<echo=TRUE, dependson='set_seed'>>=
library(dplyr)
library(tidyr)

transition_matrix = matrix(c(.7,.3,.4,.6), nrow=2, byrow=TRUE)

one_step = function(x,p=transition_matrix) {
	sample(x = 1:2, size = 1, prob=p[x,])
}

n_sims = 1e4
plyr::rdply(n_sims, {
	data.frame(monday=2) %>%
		dplyr::mutate(tuesday   = one_step(monday   ),
                              wednesday = one_step(tuesday  ),
                              thursday  = one_step(wednesday))
}) %>%
	gather(day,state, -.n) %>%
	group_by(day) %>%
	summarize(rainy_percent = mean(state==2)) %>%
	spread(day, rainy_percent) %>%
	select(monday,tuesday,wednesday,thursday) %>% 
	as.data.frame %>% round(3)
@

{\tiny above are Monte Carlo estimates of the probabilities we derived earlier 
based on \Sexpr{n_sims} simulations}

\end{frame}


\end{document}




