\documentclass[handout]{beamer}

\input{../frontmatter}
\input{../commands}

\title{Set06 - Random variables}

\begin{document}

<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment=NA, 
               fig.width=6, fig.height=5, 
               size='tiny', 
               out.width='0.8\\textwidth', 
               fig.align='center', 
               message=FALSE,
               echo=FALSE,
               cache=TRUE)
options(width=120)
@

<<libraries, message=FALSE, warning=FALSE>>=
library(dplyr)
library(ggplot2)
@

<<set_seed>>=
set.seed(2)
@

\frame{\maketitle}


\begin{frame}
\frametitle{Discrete random variables}
\setkeys{Gin}{width=0.15\textwidth}

\begin{definition}
A \alert{random variable} $X$ is a function $X:\mOmega \mapsto \mathbb{R}$.
\end{definition}
\pause
Intuitive idea:  \textcolor{cyan}{If the value of a numerical variable depends on the outcome of an experiment, we call the variable a {\it random variable}.}

\pause
\begin{example}
Simple dartboard:

\end{example}
\begin{center}
\includegraphics{dartboard.pdf}
\end{center}
Imagine we throw three darts on this board one by one and we are interested in the number of times the red area has been hit. \pause
This count is a random variable!
\end{frame}


\begin{frame}
\frametitle{Dartboard example (cont.)}

\begin{itemize}
\item Let $X$ the number of times that the red area is hit out of three throws. \pause
\item $X(\omega)=  x$, if the outcome $\omega$ has $x$ hits to the red area, and $3-x$ hits to the gray area. \pause
\item Thus, the set of possible values for $X(\omega)$ is $\{0,1,2,3\}$. \pause
\item To avoid cumbersome notation, we write
\[ \{X = x\} \]
for the event
\[
\{ \omega | \omega \in \Omega\ \text{ and }\ X(\omega) = x \}.
\]
\item By convention, we use a capital letter to indicate the random variable and a lower case letter to indicate a realized value of the random variable.
\end{itemize}

\end{frame}





\begin{frame}
\frametitle{8 bit example}

\begin{example}
Suppose, 8 bits are sent through a communication channel.
Each bit has a certain probability to be received incorrectly. 
We are interested in the number of bits that are received incorrectly.
\end{example}

\pause 
\begin{itemize}
\item Let $X$ be the number of incorrect bits received. \pause 
\item The possible values for $X$ are $\{0,1,2,3,4,5,6,7,8\}$. \pause
\item Example events: 
	\begin{itemize}
	\item No incorrect bits received: \pause $\{X=0\}$. \pause
	\item At least one incorrect bit received: \pause $\{X\ge 1\}$. \pause
	\item Exactly two incorrect bits received: \pause $\{X=2\}$. \pause
	\item Between two and seven (inclusive) incorrect bits received: \pause $\{2\ge X \ge 7\}$.
	\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Image of random variables}

\begin{definition}
The \alert{image} of a random variable $X$ is defined as 
\[ 
Im(X) := \{x: x=X(\omega) \text{ for some }\omega \in \Omega \}
\]
\pause
If the image is finite or countable, we have a \alert{discrete} random variable. \pause
If the image is uncountably infinite, we have a \alert{continuous} random variable.
\end{definition}

\pause

\begin{example}
\begin{itemize}
\item Put a disk drive into service, measure $Y$ = ``time till the first major failure'' and thus
		$Im(Y) = (0, \infty)$. \pause Image of $Y$ is an interval (uncountable image), so $Y$ is a
  continuous random variable.
\item Communication channel: $X$ = ``\# of incorrectly received bits'' with 
		$Im(X) = \{ 0,1,2,3,4,5,6,7,8 \}$. \pause Image of $X$ is a finite set, so $X$ is
	a discrete random variable.
\end{itemize}
\end{example}
\end{frame}




\begin{frame}
\frametitle{Distribution}

The collection of all the probabilities related to $X$ is the \alert{distribution} of $X$. \pause For a discrete random variable, the function
\[ 
P(x) = P(X=x) 
\]
is the \alert{probability mass function} (pmf) \pause and the \alert{cumulative distribution function} (cdf) is 
\[ 
F(x) = P(X\le x) =\sum_{y\le x} P(y).
\]
\pause 
The set of possible values of $X$ is called the \alert{support} of the distribution $F$. 
\end{frame}


\begin{frame}
\frametitle{Examples}
\begin{example}
Which of the following functions is a valid probability mass function?
\begin{itemize}
\item
    	\begin{tabular}{c|ccccc}
		$x$ & -3 & -1 & 0 & 5 & 7  \\
		\hline
		$P_{X}(x)$ & 0.1 & 0.45 & 0.15 & 0.25 & 0.05  \\
	\end{tabular}
    \item
    	\begin{tabular}{c|ccccc}
		$y$ & -1 & 0 & 1.5 & 3 & 4.5 \\
		\hline
		$P_{Y}(y)$ & 0.1 & 0.45 & 0.25 & -0.05 & 0.25  \\
	\end{tabular}
    \item
    	\begin{tabular}{c|ccccc}
		$z$ & 0 & 1 & 3 & 5 & 7  \\
		\hline
		$P_{Z}(z)$ & 0.22 & 0.18 & 0.24 & 0.17 & 0.18  \\
	\end{tabular}
\end{itemize}
\end{example}
\end{frame}


%     
%  \foilhead[-.8in]{\textcolor{blue}{More Examples of Discrete R.V.'s}}
%  \no {\textcolor{magenta}{Example: }} {\textcolor{cyan}{Roll of a fair die}}\\[.1in] 
% \no 	Let $Y$ be the number of spots on the upturned face of a die.\\[.15in]  	
% \no Obviously, $Y$ is a random variable with image $Im(Y)=\{1,2,3,4,5,6\}$.	\\[.1in] 
% \no Assuming, that the die is a fair die means, that the outcomes of 
% each face turning up are equally likely i.e.,
% 	probabilities of each face turning up are equal.\\[.1in]  
% \no The probability mass function for $Y$ therefore is \\[.1in] 
% \hspace*{1in}\begin{tabular}{c|cccccc}
% 		$x$ & 1 & 2 & 3 & 4 & 5& 6 \\
% 		\hline 
% 		$p_{X}(x)$ & $\frac{1}{6}$  & $\frac{1}{6}$ & $\frac{1}{6}$ & $\frac{1}{6}$ & $\frac{1}{6}$ & $ \frac{1}{6} $ 
% \end{tabular}
% 
% %\no Checkout pmf's in  Examples 3.1 and 3.3 from Baron's book.
%    
%  \foilhead[-.8in]{\textcolor{blue}{More Examples of Discrete R.V.'s}}
%  \no {\textcolor{magenta}{Example: }} {\textcolor{cyan}{Roll of a doctored die}}\\[.1in] 
%  \begin{minipage}[t]{6in} 
% 	    The diagram shows all six faces of a particular die.
% 	    If $Z$ denotes the number of spots on the upturned face after 
% 	    toss this die,
% 	    what is the probability mass function for $Z$?
% 	    
% 	    {\it Assuming, that each face of the die appears with the same 
% 	    probability, we have 1 possibility to get a 1 or a 4, and two 
% 	    possibilities for a 2 or 3 to appear, which gives a probability 
% 	    mass function for $Z$ as:
% 	     \[
% 	    \begin{array}{l||c|c|c|c}
% 		z & 1 & 2 & 3 & 4 \\ \hline
% 		p(z) & 1/6 & 1/3 & 1/3 & 1/6 
% 	    \end{array}
% 	    \]
% 	    }
% 	\end{minipage}
% 	\hfill
% 	\begin{minipage}[t]{2in}
% 	    	\vspace{0in}
%             	 \centerline {
%             	 \includegraphics[width=2in]{die-faces.pdf}
% 		}
% 	\end{minipage}
%  
% 
% 
% \foilhead[-.8in]{\textcolor{red}{Statistics of R.V.s}}
% \no {\textcolor{magenta}{Gamblers Luck!:}}
% {\textcolor{cyan}{Toss a die. Let $X$ be the number of spots turned up, then if}}\\[-.2in]
% \[
% X = \left\{ \begin{array}{rll}
% & 1,\ 3\ \text{or}\ 5 & \text{I pay you}\ \$ X\\
% & 2\ \text{or}\ 4 & \text{you pay me}\ \$ 2X \\
% & 6 & \text{no money changes hands.}
% \end{array}
% \right .
% \]
% 
% \no {\textcolor{cyan}{What amount of money do I \emph{expect} to win?}}\\[.1in]
% \no For that, we look at another function, $h(x)$, that counts the money I win with
% respect to the number of spots:
% \[
% h(x) = \left\{ \begin{array}{rl}
% -x & \text{ for } x = 1,3,5 \\
% 2x & \text{ for } x = 2,4 \\
% 0 & \text{ for } x = 6.
% \end{array}
% \right .
% \]
% 
%    \foilhead[-.8in]{\textcolor{red}{Gambling Example Continued...}}\vspace*{.05in}
% \begin{tabular}{@{In 1/6 of all tosses $X$ will be }c@{, and I will
% gain }r@{ dollars}}
% 1 & -1\\[.05in]
% 2 & 4 \\[.05in]
% 3 & -3 \\[.05in]
% 4 & 8 \\[.05in]
% 5 & -5 \\[.05in]
% 6 & 0 
% \end{tabular}
% 
% \no In total I expect to get\\[.15in] 
% \hspace*{1in} $\frac{1}{6} \cdot (-1) + \frac{1}{6} \cdot
% 4 + \frac{1}{6} \cdot (-3) + \frac{1}{6} \cdot 8 + \frac{1}{6} \cdot
% (-5) + \frac{1}{6} \cdot 0 = \frac{3}{6} = 0.5$\\[.15in]
% \no dollars per play.\\[.1in]
% \no In this example, we are calculating the \emph{expected value} of the function $h(X)$\\[.1in]
% \no We denote this by $E(h(X))$ and define this mathematically in the next lecture.


\end{document}




